
Epoch 50/200, Train Loss: 6831.1732 , Validation Loss: 767.0328
Epoch 00074: reducing learning rate of group 0 to 5.0000e-05.
Epoch 00080: reducing learning rate of group 0 to 2.5000e-05.
Epoch 00086: reducing learning rate of group 0 to 1.2500e-05.
Epoch 00092: reducing learning rate of group 0 to 6.2500e-06.
Epoch 00098: reducing learning rate of group 0 to 3.1250e-06.
Epoch 100/200, Train Loss: 6299.9142 , Validation Loss: 777.8691
Epoch 00104: reducing learning rate of group 0 to 1.5625e-06.
Epoch 00110: reducing learning rate of group 0 to 7.8125e-07.
Epoch 00116: reducing learning rate of group 0 to 3.9063e-07.
Epoch 00122: reducing learning rate of group 0 to 1.9531e-07.
Epoch 00128: reducing learning rate of group 0 to 9.7656e-08.
Epoch 00134: reducing learning rate of group 0 to 4.8828e-08.
Epoch 00140: reducing learning rate of group 0 to 2.4414e-08.
Epoch 00146: reducing learning rate of group 0 to 1.2207e-08.
Epoch 150/200, Train Loss: 6298.1876 , Validation Loss: 780.4382
Epoch 200/200, Train Loss: 6298.1106 , Validation Loss: 780.5097
Finished Training GRU, best model was epoch: 67