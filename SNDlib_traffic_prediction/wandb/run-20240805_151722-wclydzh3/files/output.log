
Epoch 10/300, Train Loss: 8932.3742 , Validation Loss: 1435.0641
Epoch 20/300, Train Loss: 8751.9471 , Validation Loss: 1314.7883
Epoch 30/300, Train Loss: 8600.2533 , Validation Loss: 1221.4408
Epoch 40/300, Train Loss: 8474.5248 , Validation Loss: 1148.5247
Epoch 50/300, Train Loss: 8367.0855 , Validation Loss: 1091.1035
Epoch 60/300, Train Loss: 8276.7019 , Validation Loss: 1045.8944
Epoch 70/300, Train Loss: 8198.7550 , Validation Loss: 1009.3576
Epoch 80/300, Train Loss: 8124.9782 , Validation Loss: 979.3918
Epoch 90/300, Train Loss: 8072.9426 , Validation Loss: 955.2796
Epoch 100/300, Train Loss: 8021.4167 , Validation Loss: 936.4820
Epoch 110/300, Train Loss: 7977.2919 , Validation Loss: 921.8163
Epoch 120/300, Train Loss: 7932.5507 , Validation Loss: 910.1429
Epoch 130/300, Train Loss: 7903.6806 , Validation Loss: 900.9016
Epoch 140/300, Train Loss: 7869.3572 , Validation Loss: 893.6623
Epoch 150/300, Train Loss: 7843.7290 , Validation Loss: 887.7985
Epoch 160/300, Train Loss: 7825.2855 , Validation Loss: 882.6711
Epoch 170/300, Train Loss: 7797.4628 , Validation Loss: 867.1073
Epoch 180/300, Train Loss: 7776.4447 , Validation Loss: 856.8984
Epoch 00189: reducing learning rate of group 0 to 5.0000e-05.
Epoch 190/300, Train Loss: 7758.1240 , Validation Loss: 855.6180
Epoch 00195: reducing learning rate of group 0 to 2.5000e-05.
Epoch 200/300, Train Loss: 7750.8191 , Validation Loss: 855.9169
Epoch 00208: reducing learning rate of group 0 to 1.2500e-05.
Epoch 210/300, Train Loss: 7741.9336 , Validation Loss: 855.8019
Epoch 00214: reducing learning rate of group 0 to 6.2500e-06.
Epoch 00220: reducing learning rate of group 0 to 3.1250e-06.
Epoch 220/300, Train Loss: 7745.3851 , Validation Loss: 857.1673
Epoch 00226: reducing learning rate of group 0 to 1.5625e-06.
Epoch 230/300, Train Loss: 7741.7656 , Validation Loss: 855.6801
Epoch 00232: reducing learning rate of group 0 to 7.8125e-07.
Epoch 00238: reducing learning rate of group 0 to 3.9063e-07.
Epoch 240/300, Train Loss: 7744.8230 , Validation Loss: 856.0199
Epoch 00244: reducing learning rate of group 0 to 1.9531e-07.
Epoch 00250: reducing learning rate of group 0 to 9.7656e-08.
Epoch 250/300, Train Loss: 7744.7342 , Validation Loss: 856.0111
Epoch 00256: reducing learning rate of group 0 to 4.8828e-08.
Traceback (most recent call last):
  File "C:\Users\beaviv\DIAMOND\SNDlib_traffic_prediction\SNDlib_run.py", line 82, in <module>
    run(training=True, test=False)
  File "C:\Users\beaviv\DIAMOND\SNDlib_traffic_prediction\SNDlib_run.py", line 77, in run
    train_loss, validation_loss, best_model = train(**train_hyperparameters)
  File "C:\Users\beaviv\DIAMOND\SNDlib_traffic_prediction\SNDlib_train.py", line 69, in train
    X_batch, y_batch = X_batch.to(device), y_batch.to(device)
KeyboardInterrupt